---
title: "xgbTree"
author: "Marietta_Dalamanga"
date: "2024-08-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#Load required libraries
library(data.table)
library(xgboost)
library(caret)
library(dplyr)
library(ggplot2)
library(purrr)
```

```{r}
train <- read.csv("./data/train.csv")
test <-read.csv("./data/test.csv")
validation <- read.csv(("./data/validation.csv"))
```

Group num of conditions >=3 together
```{r}
train$num_cond[train$num_cond >= 3] <- "3_or_more"
test$num_cond[test$num_cond >= 3] <- "3_or_more"
validation$num_cond[validation$num_cond >= 3] <- "3_or_more"
```

```{r}
colnames(train)
vars <- colnames(train)[c(3, 6, 8, 11, 12, 13, 15, 20)]
train_data <- train[, vars]
test_data <- test[, vars]
validation_data <- validation[, vars]
train_data
```






```{r}
# make factors
train_data[,c("Dvo_Code", "Abattoir", "prod_type", "Sex", "place_of_death", "num_cond")] = 
  lapply(train_data[,c("Dvo_Code","Abattoir","prod_type", "Sex", "place_of_death", "num_cond")],
                                function(x) as.factor(x))

validation_data[,c("Dvo_Code", "Abattoir", "prod_type", "Sex", "place_of_death", "num_cond")] = 
  lapply(validation_data[,c("Dvo_Code", "Abattoir","prod_type", "Sex", "place_of_death", "num_cond")],
                                function(x) as.factor(x))
```

dummify the datasets
```{r}
dmy <- dummyVars(" ~ .", data = train_data)
trsf_train <- data.frame(predict(dmy, newdata = train_data))
dmy_val <- dummyVars(" ~ .", data = validation_data)
trsf_val <- data.frame(predict(dmy_val, newdata = validation_data))

```


```{r}
set.seed(123)
playground_ind <- createDataPartition(trsf_train$days_alive, p=0.01, list=FALSE)
playground_data <- trsf_train[playground_ind, ]
playground_val_ind <- createDataPartition(trsf_val$days_alive, p=0.01, list=FALSE)
playground_val <- trsf_val[playground_val_ind, ]
```



separate response variable from predictors for train and validation set
```{r}
colnames(playground_data)
train_predictors <- playground_data[, c(1:35,37)]
train_response <- playground_data[, 36]
train_response
train_predictors

val_predictors <- playground_val[, c(1:35, 37)]
val_response <- playground_val[, 36]
```



```{r}
set.seed(123)
# Create train/test indexes which will be used in 5-Fold CV
myFolds_regression <- createFolds(train_response, k = 5)

# Check the folds
myFolds_regression %>% 
  map(
    function(x){
      summary(train_response[x])
    }
  )
```


```{r}
hyperparam_grid <- expand.grid(
  nrounds = seq(from = 100, to = 300, by = 100),
  eta = c(0.025, 0.05, 0.1, 0.3),
  max_depth = c(4, 5, 6),
  gamma = c(0, 1, 2),
  colsample_bytree = c(0.5, 0.75, 1.0),
  min_child_weight = c(1, 3, 5),
  subsample = 1
)
```

```{r}
ctrl_regression <- trainControl(
  method = "cv", # Used for configuring resampling method: in this case cross validation 
  number = 5, # Instruct that it is 5 fold-cv
  index = myFolds_regression, # Folds' indexes
  verboseIter = TRUE, # Print output of each step
  savePredictions = TRUE
)
```

```{r}
xboost_all <- caret::train(
  x = train_predictors,
  y = train_response,
  trControl = ctrl_regression,
  tuneGrid = hyperparam_grid,
  method = "xgbTree", #  this says we want XGB
  preProcess = c("zv")
)


```

```{r}
xboost_all$bestTune
xboost_all$results[which.min(xboost_all$results$RMSE), ]
```

save tuning 
```{r}
saveRDS(xboost_all, "./models/xgbTree/tuning.rds")
```


separate into healthy and unhealthy animals and use
```{r}
unhealthy_train_data <- train_data %>%
  filter(num_cond== "1" | num_cond == "2" | num_cond=="3_or_more")

healthy_train_data <- train_data %>%
  filter(num_cond =="0")

unhealthy_val_data <- validation_data %>%
  filter(num_cond== "1" | num_cond == "2" | num_cond=="3_or_more")

healthy_val_data <- validation_data %>%
  filter(num_cond =="0")
```


dummify the healthy datasets
```{r}
dmy_healthy_train <- dummyVars(" ~ .", data = healthy_train_data)
trsf_healthy_train <- data.frame(predict(dmy, newdata = healthy_train_data))
dmy_healthy_val <- dummyVars(" ~ .", data = healthy_val_data)
trsf_healthy_val <- data.frame(predict(dmy_val, newdata = healthy_val_data))

```


```{r}
set.seed(123)
playground_ind <- createDataPartition(trsf_healthy_train$days_alive, p=0.10, list=FALSE)
playground_data <- trsf_healthy_train[playground_ind, ]
playground_val_ind <- createDataPartition(trsf_healthy_val$days_alive, p=0.10, list=FALSE)
playground_val <- trsf_healthy_val[playground_val_ind, ]
```



separate response variable from predictors for train and validation set
```{r}
colnames(playground_data)
train_healthy_predictors <- playground_data[, c(1:31,37)]
train_healthy_response <- playground_data[, 36]


val_healthy_predictors <- playground_val[, c(1:31, 37)]
val_healthy_response <- playground_val[, 36]
```



```{r}
set.seed(123)
# Create train/test indexes which will be used in 5-Fold CV
myFolds_regression <- createFolds(train_healthy_response, k = 5)

# Check the folds
myFolds_regression %>% 
  map(
    function(x){
      summary(train_response[x])
    }
  )
```


```{r}
xboost_healthy <- caret::train(
  x = train_healthy_predictors,
  y = train_healthy_response,
  trControl = ctrl_regression,
  tuneGrid = hyperparam_grid,
  method = "xgbTree", #  this says we want XGB
  preProcess = c("zv")
)

```


save tuning 
```{r}
saveRDS(xboost_healthy, "./models/xgbTree/healthy_tuning.rds")
```
