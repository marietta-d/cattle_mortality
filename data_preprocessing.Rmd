---
title: "Cattle_survival"
author: "Marietta_Dalamanga"
date: "2024-07-01"
output: html_document
---

## Data Preprocessing

Load complete data file into a new object "data"

```{r}
library(tidyverse)
library(plyr)
library(dplyr)
library(visdat)
library(splitstackshape)
library(tidyr)
library(survminer)
library(data.table)
library(ggplot2)
library(lubridate)
library(tools)

```

Load complete data file into a new object "raw_data"

```{r}
raw_data <- read.csv("./data/data_complete.csv")
```

Dimensions of the dataset

```{r}
dimensions <- dim(raw_data)
paste("rows in the dataset: ", dimensions[1])
paste("columns in the dataset: ", dimensions[2])
```

Check top and bottom rows of the dataset

```{r}
print(head(raw_data))
print(tail(raw_data))
```
An overview of the data and datatype of the variables

```{r}
glimpse(raw_data)
```
Unnamed column is a second index column that can be removed. 
Most of the variable's data-type is character and we should change them to the appropriate datatype.
We have 10 categorical variables , 2 date variables and 1 numerical

```{r}
data <- raw_data[, -1]
head(data)
```



### Data preprocessing
#### Assign the appropriate datatype to variables

change data type of columns as follows:
factor: Herd_Id, Abbatoir, Dvo_Code, Breed, Sex, Abattoir_._Died_on_Farm, Beef_or_Dairy, ConditionsbyAI
Dates: Dob, Dod
integer: Total_Conditions_per_Animal

Before that we have to change all empty characters to Nan 
```{r}
data[data==""] <- NA
```

```{r}
glimpse(data)
```

Date of birth and Date of death variables to date data-type
```{r}
data[,c("Dob", "Dod")] = lapply(data[,c("Dob", "Dod")],
                                function(x) as.Date(x, format="%m/%d/%Y"))
```


```{r}
glimpse(data)
```

### Delete rows where the DVO code is wrong (all dvo codes above 10)

11898 observations have wrong Dvo and we cannot find the value from Patch area code

```{r}
# 11898 
data <- data %>%
  subset(!data$Dvo_Code >10)

```


Change Data type to factor
```{r}
data[,c("Herd_Id", "Abbatoir", "Dvo_Code", "Patch_Area", "Breed", "Sex", "Abattoir_._Died_on_Farm", "Beef_or_Dairy", "ConditionsbyAI")] = 
  lapply(data[,c("Herd_Id", "Abbatoir", "Dvo_Code", "Patch_Area", "Breed", "Sex", "Abattoir_._Died_on_Farm", "Beef_or_Dairy", "ConditionsbyAI")],
                                function(x) as.factor(x))
```


```{r}
glimpse(data)
```

Check how many levels for each factor
```{r}
sapply(data, nlevels)
```


#### Check for duplicated entries

We use data.table library because it was more efficient with the large dataset
```{r}
data_table <- data.table(data)
duplicated_rows_datatable <- duplicated(data_table)
sum(duplicated_rows_datatable)
```

### Handling missing values

find missing values pattern

```{r}
colSums(is.na(data))
```


```{r}
sapply(data, function(x) mean(is.na(x)) * 100)
```


Delete Patch_area column because it has too many missing values (11,702) and we can get the information from Dvo_code variable. After the removal of the wrong DVO codes the missing values in the Pach area was just 44
```{r}
clean_data <- data
clean_data$Patch_Area <- NULL

```

Delete rows with missing values in Date of birth

```{r}
clean_data <- clean_data %>%
  drop_na(Dob)
head(clean_data)
```



```{r}
colSums(is.na(clean_data))
```

### Delete rows with Sex type="U"

Delete 8 rows
```{r}
clean_data[clean_data$Sex=="U",]
clean_data <- clean_data %>%
  filter(Sex!="U")
clean_data[clean_data$Sex=="U",]
```



```{r}
clean_data <- droplevels(clean_data) 
print(sapply(clean_data, nlevels))
print(sapply(data, nlevels))
```
```{r}
clean_data
```


### Handle ConditionsbyAI variable

Conditions by AI have 6718 different levels
in each row there are multiple conditions
We will create different column for each condition

```{r}
# Handle missing values and remove trailing asterisks in the "ConditionsbyAI" column
levels(clean_data$ConditionsbyAI)
```


```{r}
clean_data %>%
  filter(ConditionsbyAI=="*") # 994 cases have * and 0 total conditions
clean_data %>%
  filter(ConditionsbyAI=="**") # 1 case have ** and 0 total conditions

```



```{r}
# Assign the value No for no disease
na_cond <- sum(is.na(clean_data$ConditionsbyAI))
zero_cond <- sum(clean_data$Total_Conditions_per_Animal==0)
paste(zero_cond-na_cond, "rows are not NA at the conditions column but have zero conditions at the Total_conditions_per_Animal column these are the cases with one or two asterisks")
```

change the asterisks to No
```{r}
levels(clean_data$ConditionsbyAI)[levels(clean_data$ConditionsbyAI)=="*"] <- "No"
levels(clean_data$ConditionsbyAI)[levels(clean_data$ConditionsbyAI)=="**"] <- "No"
```


replace NA with No
```{r}
clean_data$ConditionsbyAI[is.na(clean_data$ConditionsbyAI)] <- "No"
```


```{r}
# replace the star at the end with empty character
clean_data$ConditionsbyAI <- gsub("\\*$", "", clean_data$ConditionsbyAI)
```


```{r}
# Split the "ConditionsbyAI" column into separate rows for each condition
data_long <- clean_data %>%
  separate_rows(ConditionsbyAI, sep = "\\*") 
```


Check for duplicated rows after the unpacking of Conditions to different rows
```{r}
data_table_long <- data.table(data_long)
duplicated_rows_datatable_long <- duplicated(data_table_long)
sum(duplicated_rows_datatable_long)
```

some entries have the same condition twice. This resulted to 389 duplicated entries 
```{r}
data_long[duplicated_rows_datatable_long, ]
```

```{r}
data_table[data_table$Animal_Id== "ca31ff9491fcac3786e00ea5857607e8a15504a7", ConditionsbyAI]
```

```{r}

data_table_long[data_table_long$Animal_Id=="ca31ff9491fcac3786e00ea5857607e8a15504a7", ]
```

Exclude duplicated entries from the dataset
```{r}
data_table_long <- unique(data_table_long)
data_table_long[data_table_long$Animal_Id=="ca31ff9491fcac3786e00ea5857607e8a15504a7", ]
```


There are 15 cases where the unpacked of conditions will generate empty strings. (between the two stars)
```{r}
clean_data[clean_data$Animal_Id=="951d86f6b9083d891158f6dbb0ed49efbcfa42bd", "ConditionsbyAI"]
```

Exclude entries with empty string at Conditions
```{r}
data_table_long[data_table_long$Animal_Id=="951d86f6b9083d891158f6dbb0ed49efbcfa42bd", ]
```

```{r}
new_data_long <- subset(data_table_long, ConditionsbyAI!="")

sum(new_data_long$ConditionsbyAI == "")
```


make variable ConditionsbyAI factor again
```{r}
new_data_long$ConditionsbyAI <-as.factor(new_data_long$ConditionsbyAI)
```


```{r}
str(new_data_long)
nlevels(new_data_long$ConditionsbyAI)
```

### Feature generating for the survival analysis

For survival analysis our dataset must have one column with the age of the animal and one column with the censored status

All animals are dead thus censored status for all entries will be 2=dead, 1=censored 
```{r}
new_data_long$status <- 2
head(new_data_long)
```

We will calculate the months, years and the days alive for each animal. We will store these values as numeric

```{r}
new_data_long$days_alive <- as.numeric(difftime(new_data_long$Dod, new_data_long$Dob, units=c("days")))
```


```{r}
new_data_long$months_alive <- interval(new_data_long$Dob, new_data_long$Dod) %/% months(1)
```

```{r}
new_data_long$years_alive <- interval(new_data_long$Dob, new_data_long$Dod) %/% years(1)
```

```{r}
head(new_data_long)
```

Save the data in a new csv file
```{r}
write.csv(new_data_long, file="./data/data_long.csv")
```

#### Further survival analysis (e.g regression) 

Each animal id must be one row. Thus we will create a new dataset with One-hot encoding for the ConditionsbyAI column. (We will create a column for each condition)

```{r}
# Create a column for each unique condition
data_wide <- new_data_long %>%
  mutate(ConditionPresent = 1) %>%
  pivot_wider(names_from = ConditionsbyAI, values_from = ConditionPresent, values_fill = list(ConditionPresent = 0))

# Save the data
write.csv(data_wide, file="./data/data_wide.csv")
```


```{r}

data_wide
sum(duplicated(data_wide))

```

```{r}
data_wide[data_wide$Animal_Id=="ca6e37446ba6273258ead8171542e7568842efe1", ]
new_data_long[new_data_long$Animal_Id =="ca6e37446ba6273258ead8171542e7568842efe1", ]
```
```{r}
data_wide[data_wide$Animal_Id=="e41260ae263c07e8ce5ca68505ecb611c8c2a6ae", ]
new_data_long[new_data_long$Animal_Id =="e41260ae263c07e8ce5ca68505ecb611c8c2a6ae", ]

```


```{r}
paste("after cleaning the data we end up with", nrow(data_wide), "observations" )
paste((nrow(raw_data) - nrow(data_wide)), "rows were deleted which account for the", round(100*((nrow(raw_data) - nrow(data_wide))/nrow(raw_data)), 2), "% of the initial observations")
```


#### Combine the weather data
```{r}
# first create month and year columns for merging the data

new_data_long$Year <- as.integer(format(new_data_long$Dod, "%Y"))
new_data_long$Month <- as.integer(format(new_data_long$Dod, "%m"))

head(new_data_long)


```

Rename the levels of DVO factor

```{r}
levels(new_data_long$Dvo_Code)
levels(new_data_long$Dvo_Code) <- c("Armagh", "Ballymena", "Coleraine", "Dungannon", "Enniskillen", "LondonDerry", "Mallusk", "Newry", "Nt'Ards", "Omagh")
```


combine all weather data and add a column for the DVO

```{r}

data_dir <- "./data/weather_data"

file_list <- list.files(data_dir, pattern = "*.csv", full.names = TRUE)

# Function to read a CSV file and add a column with part of the file name
read_and_label <- function(file_path) {
  # Extract file name without extension
  file_name <- file_path_sans_ext(basename(file_path))

  label <- sub("_.*", "", file_name)
  
  # Read the CSV file
  data <- read.csv(file_path)
  
  # Add the new column with the file name part
  data$Dvo_Code <- label
  
  return(data)
}

data_list <- lapply(file_list, read_and_label)

combined_data <- bind_rows(data_list)
combined_data

```


```{r}
colnames(combined_data)
```

merge the two data sets on DVO and Dod (month and year)

```{r}
merged_data <- merge(new_data_long, combined_data, by = c("Dvo_Code", "Year", "Month"))

nrow(merged_data)
```

```{r}
nrow(new_data_long[new_data_long$Year==2022, ])

nrow(new_data_long) - nrow(merged_data)

```


We will Keep only the temperature at 2 meters

```{r}
head(merged_data)

```


```{r}
long_merged_data <- merged_data[, 1:20]
head(long_merged_data)
```



# combine the average herd size in the merged data
```{r}
data_dir <- "./data/herd_size/"

file_list <- list.files(data_dir, pattern = "*.csv", full.names = TRUE)
file_list
# Function to read a CSV file and add a column with part of the file name
read_and_label <- function(file_path) {
  # Extract file name without extension
  file_name <- file_path_sans_ext(basename(file_path))

  label <- sub("_.*", "", file_name)
  
  # Read the CSV file
  data <- read.csv(file_path)
  
  # Add the new column with the file name part
  data$Year <- label
  
  return(data)
}

data_list <- lapply(file_list, read_and_label)

combined_data <- bind_rows(data_list)

```

```{r}
str(combined_data)
combined_data$Year <- as.integer(combined_data$Year)

```


```{r}
str(long_merged_data)
# change merged_data herd id to character
long_merged_data$Herd_Id <- as.character(long_merged_data$Herd_Id)
```





```{r}
herd_id_size <- combined_data$Herd_Id

herd_id_old_data <- long_merged_data$Herd_Id

common_ids <- intersect(herd_id_size, herd_id_old_data)
common_ids
sum(herd_id_size%in%herd_id_old_data)


```
```{r}
colnames(long_merged_data)
colnames(combined_data)
combined_data <- combined_data[, 2:4]
sum(duplicated(combined_data))
no_duplicate_combine_data <- combined_data %>%
  distinct()
sum(is.na(no_duplicate_combine_data))
no_duplicate_combine_data[is.na(no_duplicate_combine_data), ]
```





```{r}
long_merged_data[long_merged_data$Herd_Id=="dcf4bd03236b1b4b06e7a6381482e96a9feabc42", ]
```

```{r}
final_merged_data <- merge(x=long_merged_data, y=no_duplicate_combine_data, by = c("Herd_Id", "Year"), all.x = TRUE)

nrow(final_merged_data)

final_merged_data[final_merged_data$Herd_Id=="fef07ff7ccf1f32b2bb31f90a8eee5c5d9ceb639", ]
```



```{r}
colnames(final_merged_data)
```




One hot encoding ConditionsbyAI for merged data

```{r}

final_merged_wide <- final_merged_data %>%
  mutate(ConditionPresent = 1) %>%
  pivot_wider(names_from = ConditionsbyAI, values_from = ConditionPresent, values_fill = list(ConditionPresent = 0))

final_merged_wide[final_merged_wide$Animal_Id=="5dd425da1403654d3dff7ea12ff3e1d1d9f82af2", ]
combined_data[combined_data$Animal_Id=="5dd425da1403654d3dff7ea12ff3e1d1d9f82af2"]
final_merged_data[final_merged_data$Animal_Id=="5dd425da1403654d3dff7ea12ff3e1d1d9f82af2", ]

final_merged_wide[final_merged_wide$Herd_Id=="fef07ff7ccf1f32b2bb31f90a8eee5c5d9ceb639", ]
combined_data[combined_data$Herd_Id=="fef07ff7ccf1f32b2bb31f90a8eee5c5d9ceb639", ]
final_merged_data[final_merged_data$Herd_Id=="fef07ff7ccf1f32b2bb31f90a8eee5c5d9ceb639", ]

```


save dataset in a csv file
```{r}
write.csv(final_merged_wide, file="./data/final_merged_wide.csv", row.names = FALSE)
```

